/* elfutils::dwarf_ref_tracker -- DWARF reference tracking in -*- C++ -*-
   Copyright (C) 2009 Red Hat, Inc.
   This file is part of Red Hat elfutils.

   Red Hat elfutils is free software; you can redistribute it and/or modify
   it under the terms of the GNU General Public License as published by the
   Free Software Foundation; version 2 of the License.

   Red Hat elfutils is distributed in the hope that it will be useful, but
   WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
   General Public License for more details.

   You should have received a copy of the GNU General Public License along
   with Red Hat elfutils; if not, write to the Free Software Foundation,
   Inc., 51 Franklin Street, Fifth Floor, Boston MA 02110-1301 USA.

   In addition, as a special exception, Red Hat, Inc. gives You the
   additional right to link the code of Red Hat elfutils with code licensed
   under any Open Source Initiative certified open source license
   (http://www.opensource.org/licenses/index.php) which requires the
   distribution of source code with any binary distribution and to
   distribute linked combinations of the two.  Non-GPL Code permitted under
   this exception must only link to the code of Red Hat elfutils through
   those well defined interfaces identified in the file named EXCEPTION
   found in the source code files (the "Approved Interfaces").  The files
   of Non-GPL Code may instantiate templates or use macros or inline
   functions from the Approved Interfaces without causing the resulting
   work to be covered by the GNU General Public License.  Only Red Hat,
   Inc. may make changes or additions to the list of Approved Interfaces.
   Red Hat's grant of this exception is conditioned upon your not adding
   any new exceptions.  If you wish to add a new Approved Interface or
   exception, please contact Red Hat.  You must obey the GNU General Public
   License in all respects for all of the Red Hat elfutils code and other
   code used in conjunction with Red Hat elfutils except the Non-GPL Code
   covered by this exception.  If you modify this file, you may extend this
   exception to your version of the file, but you are not obligated to do
   so.  If you do not wish to provide this exception without modification,
   you must delete this exception statement from your version and license
   this file solely under the GPL without exception.

   Red Hat elfutils is an included package of the Open Invention Network.
   An included package of the Open Invention Network is a package for which
   Open Invention Network licensees cross-license their patents.  No patent
   license is granted, either expressly or impliedly, by designation as an
   included package.  Should you wish to participate in the Open Invention
   Network licensing program, please visit www.openinventionnetwork.com
   <http://www.openinventionnetwork.com>.  */

#ifndef _ELFUTILS_DWARF_TRACKER
#define _ELFUTILS_DWARF_TRACKER	1

#include "subr.hh"
#include "dwarf"
#include "dwarf_comparator"
#include <tr1/unordered_map>
#include <tr1/unordered_set>

namespace elfutils
{
  // Basic tracker of tree-walk paths to DIEs.
  template<typename dw>
  class dwarf_path_finder
  {
  public:
    typedef typename dw::compile_units::const_iterator cu;
    typedef typename dw::debug_info_entry::children_type::const_iterator die;

    /* We maintain the current path down the logical DIE tree from the CU
       as a stack of iterators pointing to the DIE at each level.

       Note that the path to a DIE includes the iterator to that DIE
       itself as the last element.  This is necessary to permit sharing
       our _m_seen cache across CUs.  That sharing is useful when CUs
       might share children (i.e. they use DW_TAG_imported_unit).
       But when they do, then the "construct a derived tracker that
       jump-starts a walk" case for following a reference might be for
       a reference to another CU than the one the base tracker is
       walking (_m_root).  When path_to finds the "context" path to the
       referent, the iterator that jump-starts a new walk must be an
       iterator pointing to the referent, but must be an iterator
       somewhere in the _m_root CU's tree, not another CU's.

       NOTE!!! XXX
       This scenario means we can have a die_path in our _m_seen that
       is not from our current _m_root CU.  This is only safe as long
       as we are sure that we have already completely walked the other
       CU that die_path came from so all its entries are in _m_seen.
       This ensures that a derived tracker that jump-starts its walk at
       a path in another CU will never actually have to do any walking.
       If it ever walked, it could go awry failing to recognize the end
       of its CU's children list--it's not _m_root->children ().end ().
       If we want to generalize dwarf_path_finder so it can be used as
       a generic cache when we might not have walked whole CUs, then we
       need to change things.  We'd have to store _m_root along with
       _m_path in _m_seen so that a derived tracker made from path_to
       "context" can use the right _m_root.
    */
    typedef subr::stackish<die> die_path;

  private:
    // We use an empty list as a marker; every path includes at least one DIE.
    static inline const die_path bad_die_path ()
    {
      return die_path ();
    }
    static inline bool bad_die_path (const die_path &path)
    {
      return path.empty ();
    }

    /* We record every DIE we have seen here, mapping its .identity () to
       the die_path of parent DIEs taken to reach it, including itself.  */
    typedef std::tr1::unordered_map<dwarf::debug_info_entry::identity_type,
				    const die_path> die_map;
    die_map *_m_seen;
    bool _m_delete_seen;

    cu _m_root;

    die_path _m_path;

    explicit dwarf_path_finder (const dwarf_path_finder &)
    {
      throw std::logic_error ("not copy-constructible");
    }

    inline bool at_top () const
    {
      return _m_path.empty ();
    }

    inline const die &current_die () const
    {
      assert (!at_top ());
      return _m_path.top ();
    }

    inline die current_end () const
    {
      assert (!at_top ());
      const typename die_path::const_reverse_iterator i = ++_m_path.rbegin ();
      return (i == _m_path.rend ()
	      ? (*_m_root).children ().end ()
	      : (**i).children ().end ());
    }

  public:
    // Default constructor: an original tracker.
    inline dwarf_path_finder ()
      : _m_seen (new die_map), _m_delete_seen (true)
    {}

    // Construct a derived tracker: does its own whole walk, but sharing caches.
    inline dwarf_path_finder (const dwarf_path_finder &proto, bool)
      : _m_seen (proto._m_seen), _m_delete_seen (false)
    {}

    /* Construct a derived tracker that jump-starts a walk.
       CONTEXT is from a path_to call made on PROTO.  */
    inline dwarf_path_finder (const dwarf_path_finder &proto,
			      const die_path &context)
      : _m_seen (proto._m_seen), _m_delete_seen (false),
	_m_root (proto._m_root), _m_path (context)
    {}

    inline ~dwarf_path_finder ()
    {
      if (_m_delete_seen)
	{
	  delete _m_seen;
	  // We should never be left with a partial walk on the books.
	  assert (_m_path.empty ());
	}
    }

    // Main hooks for a normal walk.

    /* A walk object does set-up work when constructed and tear-down
       work when destroyed, so tear-down is done even for exceptions.  */
    struct walk
    {
      dwarf_path_finder *_m_tracker;
      bool _m_jumped;

      inline walk (dwarf_path_finder *w, const cu &root)
	: _m_tracker (w), _m_jumped (false)
      {
	assert (_m_tracker->_m_path.empty ());
	_m_tracker->_m_root = root;
      }

      inline ~walk ()
      {
	if (_m_jumped)
	  _m_tracker->_m_path.clear ();
	else
	  assert (_m_tracker->_m_path.empty ());
      }

      inline void jump (const typename dw::debug_info_entry &there)
      {
	_m_jumped = true;
	_m_tracker->prime_path_to (there);
      }
    };

    /* A step object does pre-order work when constructed and post-order
       work when destroyed, so post-order is done even for exceptions.
       While this object lives, HERE is on the _m_path stack.  */
    struct step
    {
      dwarf_path_finder *_m_walker;
      inline step (dwarf_path_finder *w, const die &here,
		   bool record = true)
	: _m_walker (w)
      {
	// Append this DIE to the path we'll record for it and its children.
	_m_walker->_m_path.push (here);

	// Record the path down from the CU to see this DIE.
	assert (!bad_die_path (_m_walker->_m_path));
	if (record)
	  _m_walker->_m_seen->insert (std::make_pair ((*here).identity (),
						      _m_walker->_m_path));
      }
      inline ~step ()
      {
	_m_walker->_m_path.pop ();
      }
    };

    bool prime_path_to (const typename dw::debug_info_entry &here,
			dwarf::debug_info_entry::identity_type id)
    {
      if (here.identity () == id)
	return true;

      for (typename dw::debug_info_entry::children_type::const_iterator i
	     = here.children ().begin ();
	   i != here.children ().end ();
	   ++i)
	{
	  step into (this, i);
	  if (prime_path_to (*i, id))
	    return true;
	}

      return false;
    }

    inline void unreachable (const typename dw::debug_info_entry &) const
    {
      throw std::runtime_error ("DIE not reachable from CU!");
    }

    inline void prime_path_to (const typename dw::debug_info_entry &there)
    {
      assert (at_top ());
      bool found = prime_path_to (*_m_root, there.identity ());
      assert (at_top ());
      if (likely (found))
	_m_path = (*_m_seen)[there.identity ()];
      else
	unreachable (there);
    }

    // Random access to a DIE, find the path of the walk that gets there.
    inline const die_path &path_to (const die &a)
    {
      return path_to (*a);
    }

    inline const die_path &path_to (const typename dw::debug_info_entry &a)
    {
      const dwarf::debug_info_entry::identity_type id = a.identity ();
      std::pair<typename die_map::iterator, bool> found
	= _m_seen->insert (std::make_pair (id, bad_die_path ()));
      if (found.second
	  /* It's not in our _m_seen map.  Our main walk recording
	     into _m_seen is exhaustive, so this can only be a forward
	     reference.  That is, we didn't already hit this DIE in
	     our top-level walk and so it is not in _m_seen yet.

	     We must do a separate walk to find it.  Since we know
	     this is a forward reference, we don't have to start a
	     fresh walk from the root, just momentarily wind forward
	     from where we are.  */
	  && !walk_down_to (id, found.first)
	  && !walk_over_to (id, found.first)
	  && !walk_up_to (id, found.first))
	unreachable (a);
      assert (&found.first->second != NULL);
      assert (!bad_die_path (found.first->second));
      return found.first->second;
    }

  private:
    inline bool walk_to (const typename die::value_type &here,
			 dwarf::debug_info_entry::identity_type there,
			 typename die_map::iterator &cache)
    {
      return walk_to (here.children ().begin (),
		      here.children ().end (),
		      there, cache);
    }

    bool walk_to (die it, const die &end,
		  dwarf::debug_info_entry::identity_type there,
		  typename die_map::iterator &cache)
    {
      for (; it != end; ++it)
	{
	  /* Note that we compare identities here, rather than passing down
	     a THERE iterator and comparing iterators.  In dwarf_output, we
	     can have multiple iterators into distinct children_type vectors
	     that all point to the same entry.  A reference could be one of
	     these iterators, and all mean the same entry.  */
	  if ((*it).identity () == there)
	    {
	      /* We can't keep the old CACHE iterator and avoid this
		 find (hash lookup), because there could have been
		 other insertions in the map since it was taken.
		 Those can invalidate old iterators.  */
	      cache = _m_seen->find (there);
	      _m_seen->erase (cache);

	      // Include the iterator we've found in the path to itself.
	      step into (this, it, false);

	      cache = _m_seen->insert (cache, std::make_pair (there, _m_path));
	      return true;
	    }
	  else
	    {
	      /* Do "step into" even for !has_children ()
		 because it records this child in _m_seen,
		 which we will rely on later.  */
	      step into (this, it);
	      const typename die::value_type &child = *it;
	      if (child.has_children () && walk_to (child, there, cache))
		return true;
	    }
	}
      return false;
    }

    /* First descend into the current DIE's children.
       _m_path already has the current DIE, so it is ready to go.  */
    // XXX is a reference to an owned DIE really possible??
    inline bool walk_down_to (dwarf::debug_info_entry::identity_type there,
			      typename die_map::iterator &cache)
    {
      if ((*current_die ()).has_children ())
	{
	  /* It's common to have a reference to the next sibling DIE.
	     So bypass the descent to HERE's children if THERE is
	     HERE's immediate next sibling.  */

	  die next = current_die ();
	  ++next;

	  if (next == current_end () || there != (*next).identity ())
	    return walk_to (*current_die (), there, cache);
	}
      return false;
    }

    /* A step_up object saves _m_path when constructed
       and restores it when destroyed.  */
    struct step_up
    {
      dwarf_path_finder *_m_walker;
      die_path _m_save;
      inline step_up (dwarf_path_finder *w)
	: _m_walker (w), _m_save (w->_m_path)
      {}
      inline ~step_up ()
      {
	_m_walker->_m_path.swap (_m_save);
      }
    };

    /* A step_back object pops the current DIE off _m_path when
       constructed, and pushes it back when destroyed.  */
    struct step_back
    {
      dwarf_path_finder *_m_walker;
      const die _m_here;
      inline step_back (dwarf_path_finder *w, die &copy)
	: _m_walker (w), _m_here (w->current_die ())
      {
	w->_m_path.pop ();
	copy = _m_here;
      }
      inline ~step_back ()
      {
	_m_walker->_m_path.push (_m_here);
      }
    };

    /* Now wind the walk forward starting from the current DIE's
       immediate sibling.  */
    inline bool walk_over_to (dwarf::debug_info_entry::identity_type there,
			      typename die_map::iterator &cache)
    {
      const die end = current_end (); // Taken before step_back.
      die next;
      step_back from (this, next);
      ++next;

      return walk_to (next, end, there, cache);
    }

    /* Now wind the walk forward starting from the current DIE's
       parent's immediate sibling.  */
    inline bool walk_up_to (dwarf::debug_info_entry::identity_type there,
			    typename die_map::iterator &cache)
    {
      if (!at_top ())
	{
	  step_up from (this);
	  while (_m_path.pop (), !at_top ())
	    if (walk_over_to (there, cache))
	      return true;
	}
      return false;
    }
  };

  // Standard tracker.
  template<class dwarf1, class dwarf2>
  class dwarf_ref_tracker : public dwarf_tracker_base<dwarf1, dwarf2>
  {
  private:
    typedef dwarf_tracker_base<dwarf1, dwarf2> _base;

    explicit dwarf_ref_tracker (const dwarf_ref_tracker &)
       : _base ()
    {
      throw std::logic_error ("not copy-constructible");
    }

  public:
    typedef typename _base::cu1 cu1;
    typedef typename _base::cu2 cu2;
    typedef typename _base::die1 die1;
    typedef typename _base::die2 die2;
    class reference_match;

  protected:
    typedef dwarf_path_finder<dwarf1> tracker1;
    typedef dwarf_path_finder<dwarf2> tracker2;

    tracker1 _m_left;
    tracker2 _m_right;

    struct ref_hasher : public std::unary_function<die2, size_t>
    {
      inline size_t operator () (const die2 &i) const
      {
	return (*i).identity ();
      }
    };

    struct same_ref : public std::equal_to<die2>
    {
      inline bool operator () (const die2 &a, const die2 &b) const
      {
	return (*a).identity () == (*b).identity ();
      }
    };

    typedef std::tr1::unordered_map<dwarf::debug_info_entry::identity_type,
				    reference_match *> active_map;
    active_map _m_active;

    typedef std::pair<const die2 *,
		      std::tr1::unordered_set<die2, ref_hasher, same_ref>
		      > equiv_list;
    typedef std::tr1::unordered_map<dwarf::debug_info_entry::identity_type,
				    equiv_list> equiv_map;
    equiv_map *_m_equiv;
    bool _m_delete_equiv;

    inline equiv_list *equiv_to (const die1 &a)
    {
      return &(*_m_equiv)[a->identity ()];
    }

    struct equal_enough : public std::binary_function<die1, die2, bool>
    {
      inline bool operator () (const die1 &a, const die2 &b)
      {
	return dwarf_comparator<dwarf1, dwarf2>::equal_enough (*a, *b);
      }
    };

  public:
    inline dwarf_ref_tracker ()
      : _m_equiv (new equiv_map), _m_delete_equiv (true)
    {}

    inline dwarf_ref_tracker (const tracker1 &proto)
      : _m_left (proto, true),
	_m_equiv (new equiv_map), _m_delete_equiv (true)
    {}

    inline ~dwarf_ref_tracker ()
    {
      if (_m_delete_equiv)
	delete _m_equiv;
    }

    inline void reset ()
    {
      _m_equiv->clear ();
      assert (!_m_right->_m_delete_seen);
      _m_right._m_seen->clear ();
    }

    struct walk
    {
      typename tracker1::walk _m_left;
      typename tracker2::walk _m_right;

      inline walk (dwarf_ref_tracker *w, const cu1 &a, const cu2 &b)
	: _m_left (&w->_m_left, a), _m_right (&w->_m_right, b)
      {}

      // Wind forward to cache everything up through A and B.
      inline void jump (const typename dwarf1::debug_info_entry &a,
			const typename dwarf2::debug_info_entry &b)
      {
	_m_left.jump (a);
	_m_right.jump (b);
      }
    };

    struct step
    {
      typename tracker1::step _m_left;
      typename tracker2::step _m_right;

      inline step (dwarf_ref_tracker *w, const die1 &a, const die2 &b)
	: _m_left (&w->_m_left, a), _m_right (&w->_m_right, b)
      {}
    };

    typedef typename tracker1::die_path left_context_type;
    inline const left_context_type &left_context (const die1 &die)
    {
      return _m_left.path_to (die);
    }

    typedef typename tracker2::die_path right_context_type;
    inline const right_context_type &right_context (const die2 &die)
    {
      return _m_right.path_to (die);
    }

    // Very cheap check for an obvious mismatch of contexts.
    inline bool context_quick_mismatch (const left_context_type &a,
					const right_context_type &b)

    {
      return a.size () != b.size ();
    }

    // Full match when context_quick_mismatch has returned false.
    inline bool context_match (const left_context_type &a,
			       const right_context_type &b)
    {
      equal_enough equalator;
      // Ignore the top of the stack, which is the target DIE itself.
      return a.equal (b, equalator, 1);
    }

    class reference_match
    {
      friend class dwarf_ref_tracker;
    protected:
      equiv_list *_m_lhs;
      typename active_map::value_type *_m_rhs;
      active_map *_m_active;

    public:

      inline reference_match ()
	: _m_lhs (NULL), _m_rhs (NULL), _m_active (NULL)
      {}

      inline ~reference_match ()
      {
	if (_m_lhs != NULL)
	  _m_lhs->first = NULL;
	if (_m_rhs != NULL)
	  _m_active->erase (_m_rhs->first);
      }
    };

    /* A prematch during the main tree walk does the same cache lookup
       as real reference matching.  But it doesn't record itself as a
       "walk in progress" for the circularity-catching logic.  Doing so
       can break that logic for comparison purposes.  Since we key our
       cache on identity, a lookup can hit a shared DIE as well as one
       that is truly involved in our current walk.  If we hit a shared
       DIE on the main walk, and within that recursion (i.e. somewhere
       in its children or along its own references) we encounter a
       circularity, we'd take the main-walk's equiv_list record as the
       root of the circularity on one side, while on the other side the
       DIEs may not have been shared and so the same circularity is
       actually rooted at the second instance of an identical DIE.  */
    inline bool prematch (reference_match &matched,
			  const die1 &a, const die2 &b)
    {
      return reference_matched (matched, a, b, false);
    }

    inline bool
    reference_matched (reference_match &matched, const die1 &a, const die2 &b,
		       bool record = true)
    {
      equiv_list *elt = equiv_to (a);
      if (elt->first == NULL)
	{
	  matched._m_lhs = elt;

	  if (record)
	    /* Record that we have a walk in progress crossing A.
	       When MATCHED goes out of scope in our caller, its
	       destructor will reset ELT->first to clear this record.  */
	    elt->first = &b;

	  // Short-circuit if we have already matched B to A.
	  return elt->second.find (b) != elt->second.end ();
	}

      /* We have a circularity on the left-hand side.  We can tell because
	 ELT->first remains set from an outer recursion still in progress.

	 The circular chain of references rooted at A matches B if B is
	 also the root of its own circularity and everything along those
	 parallel chains matches.  If the chains hadn't matched so far,
	 we would not have kept following them to get here.

	 We recorded the B that arrived at the first comparison with A.
	 We actually record the pointer on the caller's stack rather
	 than a copy of B, just because the iterator might be larger.  */

      if ((**elt->first).identity () == (*b).identity ())
	return true;

      /* Our right-hand side is not in lock-step on a matching circularity.
	 But it's still possible this is a matching reference nonetheless.
	 A difference in the sharing vs duplication of DIEs between the
	 left-hand and right-hand sides could mean that one side's chain of
	 references reaches the same cycle sooner than the other's.

	 Consider:

	 	A1 -> A2 -> ... -> A1' -> A2 ...
	 	B1 -> B2 -> ... -> B1  -> B2 ...

	 Here A1' is an identical copy of A1, duplicated in the A object.
	 Otherwise A1 matches B1, A2 matches B2, etc.  The B walk started
	 at B1 and hits it again at the step comparing B1 to A1'.  But the
	 A walk has not hit A1 again yet (and perhaps it never will), so
	 our test above does not match.

	 This is the simplest example.  There might be more steps of the
	 reference chain that have duplicates on one side but have been
	 consolidated to a single entry on the other.  There can also be
	 multiple reference attributes at each node that differ on this
	 issue, making all manner of tangled graphs that all really match
	 the same simpler graph (and thus each other).

	 Now we start recording the state of the right-hand side reference
	 chain walk, and keep going.  When the right-hand side then becomes
	 circular, we check that it has coincided with the left-hand side.

	 This is guaranteed to terminate, at least.  It should never have
	 any false positives, since that continuing walk would eventually
	 find the differences.  We hope it doesn't have any false negatives
	 either, but to be sure of that would require more graph theory
	 than your humble writer can bring to bear.  */

      const std::pair<typename active_map::iterator, bool> p
	= _m_active.insert (std::make_pair ((*b).identity (), &matched));
      if (p.second)
	{
	  assert (p.first->second == &matched);
	  matched._m_lhs = elt;
	  matched._m_active = &_m_active;
	  matched._m_rhs = &*p.first;
	  return false;
	}

      assert (p.first->second != &matched);
      return p.first->second->_m_lhs == elt;
    }

    inline bool cannot_match (reference_match &matched,
			      const die1 &, const die2 &)
    {
      return matched._m_lhs == NULL && matched._m_rhs == NULL;
    }

    inline bool notice_match (reference_match &/*matched*/,
			      const die1 &, const die2 &/*b*/, bool matches)
    {
      /* XXX not reliable!
	 This match could be predicated on a tentative match of a
	 circular ref inside.  We can't cache that!
      if (matches && matched._m_lhs != NULL)
	matched._m_lhs->second.insert (b);
      */
      return matches;
    }

    typedef dwarf_ref_tracker subtracker;

    // Share the _m_seen maps with the prototype tracker,
    // but start a fresh walk from the given starting point.
    inline dwarf_ref_tracker (const dwarf_ref_tracker &proto, reference_match &,
			      const left_context_type &lhs,
			      const right_context_type &rhs)
      : _m_left (proto._m_left, lhs),
	_m_right (proto._m_right, rhs),
	_m_equiv (proto._m_equiv), _m_delete_equiv (false)
    {
      // We are starting a recursive consideration of LHS vs RHS.
    }
  };
};

#endif	// <elfutils/dwarf_tracker>
